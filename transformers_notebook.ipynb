{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce926d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard libararies\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e015537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e3eda75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06888d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "#ensure all operations are deterministic on gpu for reproducibility\n",
    "device=torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\" , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d26a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=\"/Users/joesh/Documents/nlp_book/data\"\n",
    "checkpoint_path=\"/Users/joesh/Documents/nlp_book/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28344d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial6/\"\n",
    "# Files to download\n",
    "pretrained_files = [\"ReverseTask.ckpt\", \"SetAnomalyTask.ckpt\"]\n",
    "\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(checkpoint_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc512884",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in pretrained_files:\n",
    "    file_path=os.path.join(checkpoint_path, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2226e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#key value\n",
    "def scaled_dot_product(k,v,q, mask=None):\n",
    "    d_k=q.size()[-1]\n",
    "    attn_logits=torch.matmul( q, k.transpose(-2,-1))  #just a standard transpose\n",
    "    attn_logits= attn_logits/math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits=attn_logits.masked_fill(mask==0, -9e15)\n",
    "    attention=F.softmax(attn_logits, dim=-1)\n",
    "    values=torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e41923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " tensor([[ 0.3367,  0.1288],\n",
      "        [ 0.2345,  0.2303],\n",
      "        [-1.1229, -0.1863]])\n",
      "K\n",
      " tensor([[ 2.2082, -0.6380],\n",
      "        [ 0.4617,  0.2674],\n",
      "        [ 0.5349,  0.8094]])\n",
      "V\n",
      " tensor([[ 1.1103, -1.6898],\n",
      "        [-0.9890,  0.9580],\n",
      "        [ 1.3221,  0.8172]])\n",
      "Values\n",
      " tensor([[ 0.5698, -0.1520],\n",
      "        [ 0.5379, -0.0265],\n",
      "        [ 0.2246,  0.5556]])\n",
      "Attention\n",
      " tensor([[0.4028, 0.2886, 0.3086],\n",
      "        [0.3538, 0.3069, 0.3393],\n",
      "        [0.1303, 0.4630, 0.4067]])\n"
     ]
    }
   ],
   "source": [
    "#Note our code supports any additional dimensionality in front of the sequence length so we can use it for batches\n",
    "#generate some random queries\n",
    "\n",
    "seq_len, d_k = 3, 2\n",
    "pl.seed_everything(42)\n",
    "q = torch.randn(seq_len, d_k)\n",
    "k = torch.randn(seq_len, d_k)\n",
    "v = torch.randn(seq_len, d_k)\n",
    "values, attention = scaled_dot_product(k,v,q)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"Values\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba8459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
